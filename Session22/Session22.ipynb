{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_P2S3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ahBVnrNc3E0U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "colab_type": "code",
        "id": "j_8LNTKJ1yGf",
        "outputId": "6f114328-df03-4e6b-ca64-bd7598e4e233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2020-02-10 16:03:51--  https://github.com/arjuntheprogrammer/TheSchoolOfAI/files/4148865/text.txt\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-repository-file-5c1aeb.s3.amazonaws.com/197807418/4148865?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200210T160351Z&X-Amz-Expires=300&X-Amz-Signature=377b7fad709da8b32b1536e27a39838ff07a35d55ad969123d515a2f3b081053&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3Bfilename%3Dtext.txt&response-content-type=text%2Fplain [following]\n",
            "--2020-02-10 16:03:51--  https://github-production-repository-file-5c1aeb.s3.amazonaws.com/197807418/4148865?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200210T160351Z&X-Amz-Expires=300&X-Amz-Signature=377b7fad709da8b32b1536e27a39838ff07a35d55ad969123d515a2f3b081053&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3Bfilename%3Dtext.txt&response-content-type=text%2Fplain\n",
            "Resolving github-production-repository-file-5c1aeb.s3.amazonaws.com (github-production-repository-file-5c1aeb.s3.amazonaws.com)... 52.216.141.236\n",
            "Connecting to github-production-repository-file-5c1aeb.s3.amazonaws.com (github-production-repository-file-5c1aeb.s3.amazonaws.com)|52.216.141.236|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10346 (10K) [text/plain]\n",
            "Saving to: ‘text.txt.1’\n",
            "\n",
            "\rtext.txt.1            0%[                    ]       0  --.-KB/s               \rtext.txt.1          100%[===================>]  10.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-10 16:03:52 (246 MB/s) - ‘text.txt.1’ saved [10346/10346]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/arjuntheprogrammer/TheSchoolOfAI/files/4148865/text.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rgOGxPDP3Wpp"
      },
      "outputs": [],
      "source": [
        "data = open('text.txt', 'r').read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "E5TKeiOp4jtl",
        "outputId": "5a59b3df-105c-4c48-ee70-6111187abc51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ]
        }
      ],
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dfj21ORa49Ps"
      },
      "outputs": [],
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UwuHVvwu6MsL"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def truncate(f, n):\n",
        "    return math.floor(f * 10 ** n) / 10 ** n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "seGHei_D5FGk"
      },
      "outputs": [],
      "source": [
        "# def sigmoid(x): # sigmoid function\n",
        "#   return (1/(1 + np.exp(-x)))\n",
        "\n",
        "# def dsigmoid(y): # derivative of sigmoid function\n",
        "#   return (sigmoid(y) * (1- sigmoid(y)))\n",
        "\n",
        "# def tanh(x): # tanh function\n",
        "#   return (np.tanh(x))\n",
        "\n",
        "# def dtanh(y): # derivative of tanh\n",
        "#   return (1 - tanh(y)**2)\n",
        "\n",
        "\n",
        "def sigmoid(x): # sigmoid function\n",
        "  return (1/(1 + np.exp(-x)))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return ((y) * (1- (y)))\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return (np.tanh(x))\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return (1 - (y)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "colab_type": "code",
        "id": "bCabpwN39kdI",
        "outputId": "cf1b899e-0d0e-4c7d-db85-d321f74282ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5\n",
            "0.25\n",
            "0.24491866240370913\n",
            "0.940014848806378\n"
          ]
        }
      ],
      "source": [
        "print((sigmoid(0)))\n",
        "print((dsigmoid(sigmoid(0))))\n",
        "print((tanh(dsigmoid(sigmoid(0)))))\n",
        "print((dtanh(tanh(dsigmoid(sigmoid(0))))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "### 0.5\n",
        "\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "### 0.25\n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "### 0.244918\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "### 0.94001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ICbWNemE6LGV"
      },
      "outputs": [],
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SFuHhqVq6Wge"
      },
      "outputs": [],
      "source": [
        "size_a = Hidden_Layer_size \n",
        "size_b = z_size\n",
        "size_c = X_size\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-bUkseNnDott"
      },
      "outputs": [],
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "\n",
        "    z = np.row_stack((h_prev, x)) # [85, 1]\n",
        "    f = sigmoid(np.add(np.matmul(p.W_f.v,z), p.b_f.v))# [10, 85][85, 1] + [10, 1] = [10, 1]\n",
        "    i = sigmoid(np.add(np.matmul(p.W_i.v,z), p.b_i.v))# [10, 85][85, 1] + [10, 1] = [10, 1]\n",
        "    C_bar = tanh(np.add(np.matmul(p.W_C.v,z), p.b_C.v))# [10, 85][85, 1] + [10, 1] = [10, 1]\n",
        "\n",
        "    C = np.add(np.multiply(f, C_prev), np.multiply(i, C_bar))#  [10, 1]\n",
        "    o = sigmoid(np.add(np.matmul(p.W_o.v,z), p.b_o.v))# [10, 85][85, 1] + [10, 1] =  [10, 1]\n",
        "    h = np.multiply(o, tanh(C))#  [10, 1]\n",
        "\n",
        "    v = np.add(np.matmul(p.W_v.v, h), p.b_v.v)# [75, 10][10, 1] + [75, 1] = [75, 1]\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y\n",
        "    # return [1,2,3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "tQO4Q4soY-h1",
        "outputId": "247f3579-2678-466d-b54d-21d797f13331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        }
      ],
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?\n",
        "\n",
        "### 9\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1GvKVWmTDt3H"
      },
      "outputs": [],
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "colab_type": "code",
        "id": "PBdHPSUeazIE",
        "outputId": "a9dbff9a-7a92-4483-f9eb-46d5fd6adf97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ]
        }
      ],
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7cinzyDivIyo"
      },
      "source": [
        "(85, 1)\n",
        "\n",
        "\n",
        "0.0\n",
        "\n",
        "\n",
        "5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zIa1jUZiGPmF"
      },
      "outputs": [],
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OJWoC3U1ITf8"
      },
      "outputs": [],
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0LTsublxIfFl"
      },
      "outputs": [],
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CQNxjTuZIia_"
      },
      "outputs": [],
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "p8SrtJiwIsSm"
      },
      "outputs": [],
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ENQYU-7AIw0t"
      },
      "outputs": [],
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bR08TvcjI4Pf"
      },
      "outputs": [],
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZVDHbMb7JNGT"
      },
      "outputs": [],
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "colab_type": "code",
        "id": "OQyNSL0iJOxH",
        "outputId": "63c0f3c2-be22-4091-b2d4-a6316e3ecbdf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD1CAYAAACm0cXeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncSIiEWOIExGJ2P8DESeBc5kHe+IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----\n",
            " feomed to MEghn gits and cases from Wuhan and restrents, one in Los Angeles County and out reported in Flongy irtives, includin't know where they Agings.\n",
            "Alial fever awaican China coud dnter for a ter \n",
            "----\n",
            "iter 50000, loss 4.657641\n"
          ]
        }
      ],
      "source": [
        "iter = 50001\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "--7GCx9GvSMC"
      },
      "source": [
        "----\n",
        "\n",
        " duoetooAl hodae Cue3  sr daohe  lti  idwhreCO Hssioa,toffy\n",
        "dutr ez po gd  Sh eyw1\n",
        "fm4  aeumerrif.t\n",
        " t dplog ho lcau0r gviaeWhc Icroa ahaeee2y oofesphtbstlotnrhes 'etthzlotedtshr vr csd  slb otaassC  o \n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "iter 900, loss 36.360101\n",
        "\n",
        "----\n",
        "\n",
        " e iar  hthafio isrbe df  ieH ,rrtnyssces\n",
        "oenpe. ohycirah neh  n   i.es r1a ento grW phseorvvezaoo sfyndng  t dWiCssyo  oniccch ree - nav oedW gufha eFsrit Tnitrli a tits e,r.rs. Ctre  c heeahhbdeehbno \n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "\n",
        "iter 900, loss 36.362127"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}